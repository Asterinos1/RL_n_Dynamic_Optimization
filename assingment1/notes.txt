Description:    
You own a web site that random users access for news. Your goal is to choose a news article to show to each user, that will maximize the chance that the user clicks on it (to read it further). This is also known as "the clickthrough rate". This is your problem setup more formally:

News Articles: 
When a user arrives at your site, there are a total of K=5 news articles you can choose from.
If you recommend article i then there is a probability that the user clicks article i, which is unknown and equal to pi.
Assume you have a total of T rounds, during which you want to maximize the number of successful recommendations (i.e., clicks)
Users:
For every user that visits your site, you know if they are: (i) male or female, and (ii) under or over 25 years old. 
The "characteristics" of each new user visiting your site, are drawn in an IID manner (i.e., the next user has no dependence on who the previous user was).
For your simulations, assume initially that there's an equal probability to draw a user from any of these classes. You can later compare this also with one scenario where these probabilities are not equal. (In all cases, assume you don't know these probabilities, beforehand, either).
User-News Preference: 
Unlike the standard bandits we've seen, it turns out that different types of users might prefer different articles! 
Let p1, p2, p3, p4 ,p5  denote the click probabilities for articles, 1,2,3,4,5, respectively. 
The taste differences are captured as follows:
female over 25: p1 = 0.8, p2 = 0.6, p3 = 0.5 , p4 = 0.4 , p5 = 0.2 
male over 25:  p1 = 0.2, p2 = 0.4, p3 = 0.5 , p4 = 0.6 , p5 = 0.8
male or female under 25:   p1 = 0.2, p2 = 0.4, p3 = 0.8 , p4 = 0.6 , p5 = 0.5
NOTE: Your algorithm initially knows NEITHER the ranking of different articles (per category), NOR the exact click probabilities.
It doesn't even know that males and females under 25 have similar preferences

Below is the code for creation of the UCB1 algorithm setup and progressive updates of counts and values for arms.

Counts: Represent recorded times when arm was pulled.
Values: Represent the known mean reward. In the case of a Bernoulli arm, values represent the probability of reward which ranges from 0 to 1.
class UCB1():
    def __init__(self, counts, values):
        self.counts = counts # Count represent counts of pulls for each arm. For multiple arms, this will be a list of counts.
        self.values = values # Value represent average reward for specific arm. For multiple arms, this will be a list of values.
        return

    # Initialise k number of arms
    def initialize(self, n_arms):
        self.counts = [0 for col in range(n_arms)]
        self.values = [0.0 for col in range(n_arms)]
        return
    
    # UCB arm selection based on max of UCB reward of each arm
    def select_arm(self):
        n_arms = len(self.counts)
        for arm in range(n_arms):
            if self.counts[arm] == 0:
                return arm
    
        ucb_values = [0.0 for arm in range(n_arms)]
        total_counts = sum(self.counts)
        
        for arm in range(n_arms):
            bonus = math.sqrt((2 * math.log(total_counts)) / float(self.counts[arm]))
            ucb_values[arm] = self.values[arm] + bonus
        return ucb_values.index(max(ucb_values))
    
    # Choose to update chosen arm and reward
    def update(self, chosen_arm, reward):
        self.counts[chosen_arm] = self.counts[chosen_arm] + 1
        n = self.counts[chosen_arm]
        
        # Update average/mean value/reward for chosen arm
        value = self.values[chosen_arm]
        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward
        self.values[chosen_arm] = new_value
        return
As per discussion in previous articles, we will use a Bernoulli distribution to represent the reward function of each arm.

class BernoulliArm():
    def __init__(self, p):
        self.p = p
    
    # Reward system based on Bernoulli
    def draw(self):
        if random.random() > self.p:
            return 0.0
        else:
            return 1.0
To proceed with any further analysis, an operational script is required to process the simulation where:

num_sims: Represents the number of independent simulations, each of length equal to ‘horizon’.
horizon: Represents the number of time steps/trials per round of simulation
def test_algorithm(algo, arms, num_sims, horizon):
    
    # Initialise variables for duration of accumulated simulation (num_sims * horizon_per_simulation)
    chosen_arms = [0.0 for i in range(num_sims * horizon)]
    rewards = [0.0 for i in range(num_sims * horizon)]
    cumulative_rewards = [0 for i in range(num_sims * horizon)]
    sim_nums = [0.0 for i in range(num_sims *horizon)]
    times = [0.0 for i in range (num_sims*horizon)]
    
    for sim in range(num_sims):
        sim = sim + 1
        algo.initialize(len(arms))
        
        for t in range(horizon):
            t = t + 1
            index = (sim -1) * horizon + t -1
            sim_nums[index] = sim
            times[index] = t
            
            # Selection of best arm and engaging it
            chosen_arm = algo.select_arm()
            chosen_arms[index] = chosen_arm
            
            # Engage chosen Bernoulli Arm and obtain reward info
            reward = arms[chosen_arm].draw()
            rewards[index] = reward
            
            if t ==1:
                cumulative_rewards[index] = reward
            else:
                cumulative_rewards[index] = cumulative_rewards[index-1] + reward
                
            algo.update(chosen_arm, reward)
    
    return [sim_nums, times, chosen_arms, rewards, cumulative_rewards]

Based on the sample python code for UCB algorithm create a python code to solve the problem and produce plots that show the sublinear regret of your algorithm.



This Python code implements the click-through rate problem using UCB algorithm in Python and has only a single user-type with his click probabilities.
Update the code with the following:
it turns out that different types of users might prefer different articles! 
Let p1, p2, p3, p4 ,p5  denote the click probabilities for articles, 1,2,3,4,5, respectively. 
The taste differences are captured as follows:
female over 25: p1 = 0.8, p2 = 0.6, p3 = 0.5 , p4 = 0.4 , p5 = 0.2 
male over 25:  p1 = 0.2, p2 = 0.4, p3 = 0.5 , p4 = 0.6 , p5 = 0.8
male or female under 25:   p1 = 0.2, p2 = 0.4, p3 = 0.8 , p4 = 0.6 , p5 = 0.5
The code needs to adapt for each type of user.

